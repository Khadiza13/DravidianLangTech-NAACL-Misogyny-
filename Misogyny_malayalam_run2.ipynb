{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10404788,
          "sourceType": "datasetVersion",
          "datasetId": 6447553
        },
        {
          "sourceId": 10404789,
          "sourceType": "datasetVersion",
          "datasetId": 6447554
        },
        {
          "sourceId": 10404793,
          "sourceType": "datasetVersion",
          "datasetId": 6447557
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Misogyny_malayalam_run2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khadiza13/DravidianLangTech-NAACL-Misogyny-/blob/main/Misogyny_malayalam_run2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:18.783803Z",
          "iopub.execute_input": "2025-01-09T14:41:18.784137Z",
          "iopub.status.idle": "2025-01-09T14:41:19.078528Z",
          "shell.execute_reply.started": "2025-01-09T14:41:18.784112Z",
          "shell.execute_reply": "2025-01-09T14:41:19.077817Z"
        },
        "id": "ScV5XyNYFTZ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA_PATH = '/kaggle/input/train-dataset/train/train.csv'\n",
        "EVAL_DATA_PATH = '/kaggle/input/eval-dataset/dev/dev.csv'\n",
        "TEST_DATA_PATH = '/kaggle/input/test-dataset/test/test.csv'\n",
        "# Load the training data\n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "eval_data = pd.read_csv(EVAL_DATA_PATH)\n",
        "test_data = pd.read_csv(TEST_DATA_PATH)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:22.123516Z",
          "iopub.execute_input": "2025-01-09T14:41:22.123991Z",
          "iopub.status.idle": "2025-01-09T14:41:22.177758Z",
          "shell.execute_reply.started": "2025-01-09T14:41:22.123961Z",
          "shell.execute_reply": "2025-01-09T14:41:22.176918Z"
        },
        "id": "mIsPNR8cFTZ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_counts = train_data['labels'].value_counts()\n",
        "eval_label_counts = eval_data['labels'].value_counts()\n",
        "\n",
        "\n",
        "# Display the counts\n",
        "print(\"Training Data Label Distribution:\")\n",
        "print(train_label_counts)\n",
        "\n",
        "print(\"\\nValidation Data Label Distribution:\")\n",
        "print(eval_label_counts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:25.00795Z",
          "iopub.execute_input": "2025-01-09T14:41:25.008279Z",
          "iopub.status.idle": "2025-01-09T14:41:25.030411Z",
          "shell.execute_reply.started": "2025-01-09T14:41:25.00825Z",
          "shell.execute_reply": "2025-01-09T14:41:25.029531Z"
        },
        "id": "KNFPeG86FTZ8",
        "outputId": "22392efd-b72d-4089-990e-b2a739931dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training Data Label Distribution:\nlabels\n0    381\n1    259\nName: count, dtype: int64\n\nValidation Data Label Distribution:\nlabels\n0    97\n1    63\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:27.947988Z",
          "iopub.execute_input": "2025-01-09T14:41:27.948419Z",
          "iopub.status.idle": "2025-01-09T14:41:27.956987Z",
          "shell.execute_reply.started": "2025-01-09T14:41:27.948381Z",
          "shell.execute_reply": "2025-01-09T14:41:27.955869Z"
        },
        "id": "dSuagtBoFTZ9",
        "outputId": "bb41c1eb-57bf-4cad-d7c1-febb2b2636bc"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(640, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data.shape\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:30.286316Z",
          "iopub.execute_input": "2025-01-09T14:41:30.286654Z",
          "iopub.status.idle": "2025-01-09T14:41:30.292397Z",
          "shell.execute_reply.started": "2025-01-09T14:41:30.286616Z",
          "shell.execute_reply": "2025-01-09T14:41:30.291347Z"
        },
        "id": "f9E2eBO6FTZ-",
        "outputId": "2723a997-c299-46f5-ab1a-eb9a8e60ca5d"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(160, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:32.647013Z",
          "iopub.execute_input": "2025-01-09T14:41:32.647325Z",
          "iopub.status.idle": "2025-01-09T14:41:32.652372Z",
          "shell.execute_reply.started": "2025-01-09T14:41:32.647301Z",
          "shell.execute_reply": "2025-01-09T14:41:32.65157Z"
        },
        "id": "O7dpejuNFTZ_",
        "outputId": "80178358-e10d-4799-9a4f-9cc214b482d5"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(200, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:41:35.029502Z",
          "iopub.execute_input": "2025-01-09T14:41:35.029785Z",
          "iopub.status.idle": "2025-01-09T14:41:35.041777Z",
          "shell.execute_reply.started": "2025-01-09T14:41:35.029765Z",
          "shell.execute_reply": "2025-01-09T14:41:35.041023Z"
        },
        "id": "hHu3wK8_FTZ_",
        "outputId": "90a21524-5ea9-41ce-8b72-87e217b93cd8"
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   image_id  labels                                     transcriptions\n0       888       0  \\nഈ ചാടി ഓടി നടക്കണ മനുഷ്യനാണോടാ നിങ്ങളിത്രേം ...\n1       554       1  മലയാള സിനിമയുടെ ഭാവി വടറാണി ഇവൾ തന്നെ നല്ല കുഴ...\n2       556       1  ഒന്ന് പെറ്റത് ആണെങ്കിലും .. മുലയും വയറും ചാടിയ...\n3       484       1  ഓൺലൈൻ പരിചയപ്പെട്ടവനെ കളി തരാമെന്ന് പറഞ്ഞു അപ്...\n4       370       0  കാമുകിയും അൺലിമിറ്റഡ് നെറ്റ് ഓഫറുംഉള്ള പയ്യന്റ...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>labels</th>\n      <th>transcriptions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>888</td>\n      <td>0</td>\n      <td>\\nഈ ചാടി ഓടി നടക്കണ മനുഷ്യനാണോടാ നിങ്ങളിത്രേം ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>554</td>\n      <td>1</td>\n      <td>മലയാള സിനിമയുടെ ഭാവി വടറാണി ഇവൾ തന്നെ നല്ല കുഴ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>556</td>\n      <td>1</td>\n      <td>ഒന്ന് പെറ്റത് ആണെങ്കിലും .. മുലയും വയറും ചാടിയ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>484</td>\n      <td>1</td>\n      <td>ഓൺലൈൻ പരിചയപ്പെട്ടവനെ കളി തരാമെന്ന് പറഞ്ഞു അപ്...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>370</td>\n      <td>0</td>\n      <td>കാമുകിയും അൺലിമിറ്റഡ് നെറ്റ് ഓഫറുംഉള്ള പയ്യന്റ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_scheduler\n",
        "from transformers import ViTModel, ViTFeatureExtractor\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize tokenizer and model for Malayalam BERT\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"l3cube-pune/malayalam-bert\",\n",
        "    model_max_length=128,\n",
        "    use_fast=True\n",
        ")\n",
        "\n",
        "# Malayalam BERT model\n",
        "text_model = AutoModel.from_pretrained(\"l3cube-pune/malayalam-bert\")\n",
        "\n",
        "# Resize token embeddings to ensure alignment with tokenizer\n",
        "text_model.resize_token_embeddings(len(text_tokenizer))\n",
        "\n",
        "# Vision Transformer model and feature extractor\n",
        "vision_feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "vision_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "\n",
        "# Custom Dataset class\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, image_path, max_len=128, is_test=False):\n",
        "        self.texts = data['transcriptions'].fillna(\"\").values\n",
        "        self.image_ids = data['image_id'].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.image_path = image_path\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "        if not is_test:\n",
        "            self.labels = data['labels'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        image_id = self.image_ids[idx]\n",
        "\n",
        "        # Handle unknown tokens explicitly\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        image = Image.open(f\"{self.image_path}/{image_id}.jpg\").convert(\"RGB\")\n",
        "        image = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])(image)\n",
        "\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'image': image,\n",
        "        }\n",
        "\n",
        "        if not self.is_test:\n",
        "            item['label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "# Define multimodal model\n",
        "class MultimodalModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "\n",
        "        # Text encoder using Malayalam BERT\n",
        "        self.text_encoder = text_model\n",
        "\n",
        "        # Image encoder using Vision Transformer\n",
        "        self.image_encoder = vision_model\n",
        "\n",
        "        # Combined classifier\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(768 + 768, 512),  # Malayalam BERT hidden size + ViT hidden size\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.1),\n",
        "            torch.nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, image):\n",
        "        # Encode text\n",
        "        text_outputs = self.text_encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        text_cls = text_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        # Encode image\n",
        "        image_outputs = self.image_encoder(pixel_values=image)\n",
        "        image_cls = image_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        # Concatenate features\n",
        "        combined_features = torch.cat((text_cls, image_cls), dim=1)\n",
        "\n",
        "        # Classify\n",
        "        outputs = self.classifier(combined_features)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = \"/kaggle/input/train-dataset/train\"\n",
        "eval_image_dir = \"/kaggle/input/eval-dataset/dev\"\n",
        "test_image_dir = \"/kaggle/input/test-dataset/test\"\n",
        "\n",
        "# Prepare datasets and data loaders\n",
        "train_dataset = MemeDataset(train_data, text_tokenizer, train_image_dir)\n",
        "eval_dataset = MemeDataset(eval_data, text_tokenizer, eval_image_dir)\n",
        "test_dataset = MemeDataset(test_data, text_tokenizer, test_image_dir, is_test=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize model, optimizer, and scheduler\n",
        "model = MultimodalModel()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "epochs = 5\n",
        "num_training_steps = epochs * len(train_loader)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(model, data_loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        images = batch['image']\n",
        "        labels = batch['label']\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, image=images)\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(data_loader), correct / total\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            images = batch['image']\n",
        "            labels = batch['label']\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, image=images)\n",
        "            loss_fn = torch.nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(data_loader), correct / total, all_labels, all_preds\n",
        "\n",
        "def predict_test(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            images = batch['image']\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, image=images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_loader)\n",
        "    eval_loss, eval_acc, _, _ = evaluate(model, eval_loader)\n",
        "\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Validation Loss: {eval_loss:.4f}, Validation Accuracy: {eval_acc:.4f}\")\n",
        "\n",
        "# Final evaluation\n",
        "print(\"\\nFinal Evaluation:\")\n",
        "_, _, all_labels, all_preds = evaluate(model, eval_loader)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Non-Misogyny', 'Misogyny']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T14:50:00.631251Z",
          "iopub.execute_input": "2025-01-09T14:50:00.6316Z",
          "iopub.status.idle": "2025-01-09T15:49:24.981232Z",
          "shell.execute_reply.started": "2025-01-09T14:50:00.631572Z",
          "shell.execute_reply": "2025-01-09T15:49:24.980116Z"
        },
        "id": "LEMFl5ohFTaA",
        "outputId": "e5fecc7b-b15c-400c-bb0b-3f6f696d3be9",
        "colab": {
          "referenced_widgets": [
            "750f238e13c9479495754efdd47bf99b",
            "17e93ccb7c39464aa4acb8de6d0bfd00",
            "1f59d1679bab4b1281a5baa7eef89ed1",
            "91beb1e68a3e406481e30cffa9862180",
            "a7e2d0ac858b42a58331d9484cbe1855",
            "201b28a00ceb4dfda263e306ed5f75d5",
            "08a79a437a434154a2da569a5a81affb",
            "95fb1d52688144fd95de96a853924f9f",
            "4e7dd8bd82e94be7970f363b7948ca7a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/454 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "750f238e13c9479495754efdd47bf99b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e93ccb7c39464aa4acb8de6d0bfd00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/6.41M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f59d1679bab4b1281a5baa7eef89ed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91beb1e68a3e406481e30cffa9862180"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e2d0ac858b42a58331d9484cbe1855"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/951M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "201b28a00ceb4dfda263e306ed5f75d5"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertModel were not initialized from the model checkpoint at l3cube-pune/malayalam-bert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08a79a437a434154a2da569a5a81affb"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95fb1d52688144fd95de96a853924f9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e7dd8bd82e94be7970f363b7948ca7a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Starting training...\n\nEpoch 1/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 40/40 [10:56<00:00, 16.42s/it]\nEvaluation: 100%|██████████| 10/10 [00:51<00:00,  5.14s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training Loss: 0.5717, Training Accuracy: 0.7641\nValidation Loss: 0.5393, Validation Accuracy: 0.7312\n\nEpoch 2/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 40/40 [10:43<00:00, 16.08s/it]\nEvaluation: 100%|██████████| 10/10 [00:48<00:00,  4.89s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training Loss: 0.2921, Training Accuracy: 0.9219\nValidation Loss: 0.3654, Validation Accuracy: 0.8500\n\nEpoch 3/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 40/40 [10:47<00:00, 16.19s/it]\nEvaluation: 100%|██████████| 10/10 [00:50<00:00,  5.02s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training Loss: 0.1590, Training Accuracy: 0.9594\nValidation Loss: 0.4354, Validation Accuracy: 0.8250\n\nEpoch 4/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 40/40 [10:48<00:00, 16.20s/it]\nEvaluation: 100%|██████████| 10/10 [00:49<00:00,  4.93s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training Loss: 0.0839, Training Accuracy: 0.9844\nValidation Loss: 0.5587, Validation Accuracy: 0.8000\n\nEpoch 5/5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 40/40 [10:45<00:00, 16.14s/it]\nEvaluation: 100%|██████████| 10/10 [00:50<00:00,  5.01s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training Loss: 0.0641, Training Accuracy: 0.9906\nValidation Loss: 0.4321, Validation Accuracy: 0.8375\n\nFinal Evaluation:\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluation: 100%|██████████| 10/10 [00:49<00:00,  4.92s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nClassification Report:\n              precision    recall  f1-score   support\n\nNon-Misogyny       0.87      0.86      0.86        97\n    Misogyny       0.78      0.81      0.80        63\n\n    accuracy                           0.84       160\n   macro avg       0.83      0.83      0.83       160\nweighted avg       0.84      0.84      0.84       160\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified MemeDataset class to handle test data\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, image_path, max_len=128, is_test=False):\n",
        "        self.texts = data['transcriptions'].fillna(\"\").values\n",
        "        self.image_ids = data['image_id'].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.image_path = image_path\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "        if not is_test:\n",
        "            self.labels = data['labels'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        image_id = self.image_ids[idx]\n",
        "\n",
        "        # Handle unknown tokens explicitly\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            return_overflowing_tokens=False\n",
        "        )\n",
        "\n",
        "        # Ensure token IDs are within vocab size\n",
        "        input_ids = encoding['input_ids'].squeeze(0)\n",
        "        vocab_size = self.tokenizer.vocab_size\n",
        "        input_ids = torch.clamp(input_ids, 0, vocab_size - 1)\n",
        "\n",
        "        image = Image.open(f\"{self.image_path}/{image_id}.jpg\").convert(\"RGB\")\n",
        "        image = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])(image)\n",
        "\n",
        "        item = {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'image': image,\n",
        "        }\n",
        "\n",
        "        if not self.is_test:\n",
        "            item['label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return item\n",
        "\n",
        "def predict_test(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            images = batch['image']\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, image=images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "# Create test dataset and dataloader with is_test=True\n",
        "test_image_dir = \"/kaggle/input/test-dataset/test\"\n",
        "test_dataset = MemeDataset(test_data, text_tokenizer, test_image_dir, is_test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Get predictions\n",
        "print(\"Generating predictions for test data...\")\n",
        "test_predictions = predict_test(model, test_loader)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_data['image_id'],\n",
        "    'predictions': test_predictions\n",
        "})\n",
        "\n",
        "# Save predictions without header\n",
        "submission_df.to_csv('CUET_Novice_Malayalam_run2.csv', index=False, header=False)\n",
        "\n",
        "# Display first few predictions and verification info\n",
        "print(\"\\nFirst 10 predictions:\")\n",
        "print(submission_df.head(10))\n",
        "print(\"\\nSubmission shape:\", submission_df.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T15:54:39.487353Z",
          "iopub.execute_input": "2025-01-09T15:54:39.48772Z",
          "iopub.status.idle": "2025-01-09T15:55:40.718486Z",
          "shell.execute_reply.started": "2025-01-09T15:54:39.487689Z",
          "shell.execute_reply": "2025-01-09T15:55:40.717579Z"
        },
        "id": "MYzjjM3hFTaB",
        "outputId": "51d1f41c-c803-49d2-f385-a5d30d867ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating predictions for test data...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Testing: 100%|██████████| 13/13 [01:01<00:00,  4.71s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nFirst 10 predictions:\n    id  predictions\n0  954            0\n1  239            0\n2   61            1\n3  984            0\n4  774            0\n5  427            1\n6  960            0\n7  387            0\n8  520            0\n9  563            1\n\nSubmission shape: (200, 2)\nTest data shape: (200, 2)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('CUET_Novice.zip', 'w') as zipf:\n",
        "    zipf.write('CUET_Novice_Malayalam_run2.csv')\n",
        "\n",
        "print(\"Submission file created: CUET_Novice.zip\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T15:56:01.964433Z",
          "iopub.execute_input": "2025-01-09T15:56:01.964758Z",
          "iopub.status.idle": "2025-01-09T15:56:01.970985Z",
          "shell.execute_reply.started": "2025-01-09T15:56:01.964731Z",
          "shell.execute_reply": "2025-01-09T15:56:01.969963Z"
        },
        "id": "YURF9Lr3FTaB",
        "outputId": "9ef36fff-7917-4aca-e4a9-3abb22100b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Submission file created: CUET_Novice.zip\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}